<!DOCTYPE html>

<html lang="zh-CN">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>人工智能方面的术语 &#8212; My Notes 1.0 documentation</title>
    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=b3523f8e" />
    <link rel="stylesheet" type="text/css" href="_static/alabaster.css?v=039e1c02" />
    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js?v=8930e309"></script>
    <script src="_static/doctools.js?v=888ff710"></script>
    <script src="_static/sphinx_highlight.js?v=4825356b"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="ProtMPNN 阅读笔记 (临时)" href="protmpnn.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section id="id1">
<h1>人工智能方面的术语<a class="headerlink" href="#id1" title="Permalink to this heading">¶</a></h1>
<dl>
<dt><em>temperature</em> in NLP</dt><dd><p>用一个例子说明这个概念. 给定输入如:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="s2">&quot;the mouse eat &quot;</span>
</pre></div>
</div>
<p>让 LLM 预测下一个词是什么. LLM 会给出不同的预测和相应的 logits, 比如:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s2">&quot;cheese&quot;</span><span class="p">:</span> <span class="mi">90</span><span class="p">,</span> <span class="s2">&quot;cookie&quot;</span><span class="p">:</span> <span class="mi">78</span><span class="p">,</span> <span class="s2">&quot;dumplings&quot;</span><span class="p">:</span> <span class="mi">12</span><span class="p">}</span>
</pre></div>
</div>
<p>此 logit 并未归一, 所以要用 softmax 将其归一. 普通的 softmax 是</p>
<div class="math notranslate nohighlight">
\[S(\vec{z}) = \frac{\exp(z_i)}{\sum_i \exp(z_i)}.\]</div>
<p>temperature 参数的作用在于改变 softmax 函数在 x 方向的 “伸缩” 情况. 设
temperature 是 <span class="math notranslate nohighlight">\(\theta\)</span>, 则此时 softmax 变成</p>
<div class="math notranslate nohighlight">
\[S(\vec{z}) = \frac{ \exp(z_i / \theta) }{\sum_i \exp(z_i /\theta)}.\]</div>
<p>如果 <span class="math notranslate nohighlight">\(\theta &lt; 1\)</span>, 那么 softmax 会拉大不同 logits 值之间的差
距(倾向于 delta 函数); 若 <span class="math notranslate nohighlight">\(\theta &gt; 1\)</span>, 则 softmax 会缩小不
同 logits 之间的差距 (倾向与于均匀分布). 这就是为何此参数叫做 “温
度”, 因为温度越高, 热运动越剧烈, 则体系越倾向于均匀分布.</p>
</dd>
<dt>Label smoothing (标签平滑)</dt><dd><p>是一种提升神经网络分类模型的稳定性, 可推广性的技术 (正则化技术). 可以避免神经网
络对起预测结果过于自信 (这会导致过拟合). 其功能包括:</p>
<blockquote>
<div><ul class="simple">
<li><p>使模型不要 “过于自信”.</p></li>
<li><p>使模型的预测概率更好地体现真实的似然性.</p></li>
<li><p>让模型能更好地处理含噪的训练数据.</p></li>
</ul>
</div></blockquote>
<p>原理: 假设标签是 <span class="math notranslate nohighlight">\([0, 0, 1, 0]\)</span> (one-hot label), 则平滑后的
标签为 <span class="math notranslate nohighlight">\([\epsilon, \epsilon, 1-(K-1)\epsilon, \epsilon]\)</span>, 其
中 <span class="math notranslate nohighlight">\(\epsilon\)</span> 是一个很小的数字, <span class="math notranslate nohighlight">\(K\)</span> 是类别的数量.</p>
<p>使用场景:</p>
<blockquote>
<div><ul class="simple">
<li><p>拥有大量类别的大数据集.</p></li>
<li><p>含噪或模糊的标签.</p></li>
<li><p>概率模型.</p></li>
</ul>
</div></blockquote>
<dl class="simple">
<dt>局限和注意事项:</dt><dd><ul class="simple">
<li><p>超参数 <span class="math notranslate nohighlight">\(\epsilon\)</span> 需要精心调整, 不同的模型的最优值不同.</p></li>
<li><p>有时候标签平滑可能不会提升表现, 甚至会使结果变差.</p></li>
<li><p>由于标签平滑修改了标签, 故此技术可能增加训练所需时间.</p></li>
</ul>
</dd>
</dl>
<p>一种实现手段, 将 label smoothing 直接集成到 CrossEntropy 中 (但是
好像有问题啊):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>

<span class="c1"># Sample data</span>
<span class="n">num_classes</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">2</span>
<span class="c1"># Generate dummy data</span>
<span class="n">true_labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>  <span class="c1"># True class indices</span>
<span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">]])</span>
<span class="c1"># Label smoothing function</span>
<span class="k">def</span> <span class="nf">label_smoothed_nll_loss</span><span class="p">(</span><span class="n">lprobs</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
    <span class="n">lprobs</span> <span class="o">=</span> <span class="n">lprobs</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">lprobs</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">target</span> <span class="o">=</span> <span class="n">target</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">nll_loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">lprobs</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">target</span><span class="p">)</span>
    <span class="n">smooth_loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">lprobs</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">eps</span><span class="p">)</span> <span class="o">*</span> <span class="n">nll_loss</span> <span class="o">+</span> <span class="n">eps</span> <span class="o">*</span> <span class="n">smooth_loss</span>
    <span class="k">return</span> <span class="n">loss</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="c1"># Apply log softmax to predictions</span>
<span class="n">log_probs</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="c1"># Calculate the loss</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">label_smoothed_nll_loss</span><span class="p">(</span><span class="n">log_probs</span><span class="p">,</span> <span class="n">true_labels</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Label Smoothing Loss (PyTorch): </span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</dd>
<dt>RBF function</dt><dd><p>任何仅与输入和某向量的范数有关的函数就是 rbf 函数. 常用的 Gaussian
RBF function 定义为:</p>
<div class="math notranslate nohighlight">
\[\varphi(\vec x)_\vec{c} = e^{- \epsilon ||\vec x - \vec c||^2}.\]</div>
<p>其中 <span class="math notranslate nohighlight">\(\epsilon\)</span> 是一个常数参数, 用以调整函数的形状.</p>
<p>其他的 RBF 函数:</p>
<blockquote>
<div><ol class="arabic simple">
<li><p>Inverse quadratic: <span class="math notranslate nohighlight">\(\varphi(r) = \frac{1}{1+(\epsilon
r)^2}\)</span>.</p></li>
<li><p>Inverse multiquadric
<span class="math notranslate nohighlight">\(\varphi(r) = \frac{1}{1 + (\epsilon r)^2}\)</span>.</p></li>
</ol>
</div></blockquote>
</dd>
<dt>Permutation matrix</dt><dd><p>置换矩阵. 是一个方阵, 每一行每一列只有一个元素为 1, 其他元素均
为 0.</p>
<p>其构造方法为: 若想构造将矩阵的行按照某种方式交换的置换矩阵, 则只需
要将单位矩阵的行按相应的方式交换即可. 列置换矩阵类似, 只是需要交换
列.</p>
</dd>
</dl>
</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="index.html">My Notes</a></h1>








<h3>Navigation</h3>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="daily/202412.html">2024 年 12 月 - 日知录</a></li>
<li class="toctree-l1"><a class="reference internal" href="daily/git_usage.html">git 用法教程</a></li>
<li class="toctree-l1"><a class="reference internal" href="protmpnn.html">ProtMPNN 阅读笔记 (临时)</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">人工智能方面的术语</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
      <li>Previous: <a href="protmpnn.html" title="previous chapter">ProtMPNN 阅读笔记 (临时)</a></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>document.getElementById('searchbox').style.display = "block"</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2024, jmlv.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 7.1.2</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.13</a>
      
      |
      <a href="_sources/glossary_ai.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>